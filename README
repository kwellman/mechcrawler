usage:
To crawl all the links of a domain:

<pre>
from mechcrawler import CrawlBrowser

br = CrawlBrowser()

# start a crawl from domain.com
br.start_crawl(start_url='http://domain.com', domain='domain.com')

print br.errors()
</pre>

Thanks to Mechanize, mechcrawler can handle cookies and forms. It may be useful to have some processing before starting a crawl. For example, you can login to a site using the mechanize api, so that the crawl can access pages that require a user to be logged in.

Example:

<pre>
br.select_form(name='loginform')
br['username'] = 'username'
br['password'] = 'password'
br.submit()
</pre>
